{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89f8fa-e11b-43a7-b65e-bf2f21ac391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 128/128 [37:18<00:00, 17.49s/it, loss=1.91e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]  Loss: 4748.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 128/128 [33:24<00:00, 15.66s/it, loss=1.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]  Loss: 1020.8412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 128/128 [33:11<00:00, 15.56s/it, loss=662]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]  Loss: 974.2535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 128/128 [30:26<00:00, 14.27s/it, loss=766]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]  Loss: 890.7086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 128/128 [30:07<00:00, 14.12s/it, loss=1.34e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]  Loss: 776.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 128/128 [30:40<00:00, 14.38s/it, loss=320]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]  Loss: 677.5660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 128/128 [30:07<00:00, 14.12s/it, loss=1.14e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]  Loss: 662.8645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 128/128 [29:53<00:00, 14.01s/it, loss=416]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]  Loss: 623.5797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 128/128 [28:59<00:00, 13.59s/it, loss=690]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]  Loss: 563.3344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 128/128 [30:13<00:00, 14.17s/it, loss=564]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]  Loss: 604.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 128/128 [32:19<00:00, 15.16s/it, loss=1.27e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]  Loss: 562.6161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 128/128 [45:55<00:00, 21.53s/it, loss=541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]  Loss: 521.6514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 128/128 [34:22<00:00, 16.12s/it, loss=678]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]  Loss: 536.7205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 128/128 [1:10:01<00:00, 32.83s/it, loss=719]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]  Loss: 618.4904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20:   9%|▊         | 11/128 [02:44<31:05, 15.95s/it, loss=695]"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from models.model import UNetDeep\n",
    "from models.model import UNet2DDeep\n",
    "\n",
    "class MRISuperResDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset that takes lists (or arrays) of LR and HR 2D slices\n",
    "    and returns them as PyTorch tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self, lr_slices, hr_slices, transform=None):\n",
    "        \"\"\"\n",
    "        lr_slices, hr_slices: lists (or NumPy arrays) of shape (D, H, W)\n",
    "        transform: any optional transform function (if needed)\n",
    "        \"\"\"\n",
    "        self.lr_slices = lr_slices\n",
    "        self.hr_slices = hr_slices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr_slice = self.lr_slices[idx]  # shape [H, W]\n",
    "        hr_slice = self.hr_slices[idx]  # shape [H, W]\n",
    "\n",
    "        # Convert to float32\n",
    "        lr_slice = lr_slice.astype(np.float32)\n",
    "        hr_slice = hr_slice.astype(np.float32)\n",
    "\n",
    "        # Add channel dimension: [1, H, W]\n",
    "        lr_slice = np.expand_dims(lr_slice, axis=0)\n",
    "        hr_slice = np.expand_dims(hr_slice, axis=0)\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        lr_tensor = torch.from_numpy(lr_slice)\n",
    "        hr_tensor = torch.from_numpy(hr_slice)\n",
    "\n",
    "        if self.transform:\n",
    "            lr_tensor = self.transform(lr_tensor)\n",
    "            hr_tensor = self.transform(hr_tensor)\n",
    "\n",
    "        return lr_tensor, hr_tensor\n",
    "\n",
    "# def update_learning_rate(schedulers, val_loss):\n",
    "#     \"\"\"\n",
    "#     Update the learning rate for each scheduler.\n",
    "    \n",
    "#     For schedulers of type ReduceLROnPlateau, use scheduler.step(val_loss),\n",
    "#     otherwise, call scheduler.step() without arguments.\n",
    "    \n",
    "#     Parameters:\n",
    "#       schedulers (list): List of learning rate scheduler objects.\n",
    "#       val_loss (float): The validation loss used by ReduceLROnPlateau.\n",
    "#     \"\"\"\n",
    "#     for scheduler in schedulers:\n",
    "#         if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "#             scheduler.step(val_loss)\n",
    "#         else:\n",
    "#             scheduler.step()\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    # 1) Load pre-saved 2D slices (uncomment these lines)\n",
    "    slices_lr_axial = np.load(\"data/lr_slices_axial.npy\", allow_pickle=True)\n",
    "    slices_hr_axial = np.load(\"data/hr_slices_axial.npy\", allow_pickle=True)\n",
    "    slices_lr_coronal = np.load(\"data/lr_slices_coronal.npy\", allow_pickle=True)\n",
    "    slices_hr_coronal = np.load(\"data/hr_slices_coronal.npy\", allow_pickle=True)\n",
    "    slices_lr_sagittal = np.load(\"data/lr_slices_sagittal.npy\", allow_pickle=True)\n",
    "    slices_hr_sagittal = np.load(\"data/hr_slices_sagittal.npy\", allow_pickle=True)\n",
    "\n",
    "    all_lr_volumes = np.concatenate((slices_lr_axial, slices_lr_coronal), axis=0)\n",
    "    all_hr_volumes = np.concatenate((slices_hr_axial, slices_hr_coronal), axis=0)\n",
    "\n",
    "    # Here, we just combine everything for a single training set.\n",
    "\n",
    "    # 2) Create Dataset and DataLoader\n",
    "    train_dataset = MRISuperResDataset(all_lr_volumes, all_hr_volumes)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "    # 3) Initialize the model\n",
    "    model = UNet2DDeep(in_channels=1, out_channels=1)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # 4) Define loss & optimizer\n",
    "    criterion = nn.MSELoss()  # or L1Loss, SmoothL1Loss, etc.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "    # # Setup learning rate schedulers\n",
    "    # from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "    # scheduler_plateau = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    # scheduler_step = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    # schedulers = [scheduler_plateau, scheduler_step]\n",
    "\n",
    "\n",
    "    # 5) Train loop\n",
    "    num_epochs = 20\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "        for lr_batch, hr_batch in loop:\n",
    "            lr_batch = lr_batch.to(device)\n",
    "            hr_batch = hr_batch.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(lr_batch)\n",
    "            loss = criterion(outputs, hr_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Save model weights\n",
    "    torch.save(model.state_dict(), \"superres_unet_v4.pth\")\n",
    "    print(\"Model saved as superres_unet_v4.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8a82e-d677-49cf-9721-3727629e97e6",
   "metadata": {},
   "source": [
    "Overall Purpose\n",
    "Data Loading:\n",
    "You load pre-saved 2D slices from multiple anatomical views and combine them into one training dataset.\n",
    "\n",
    "Dataset & DataLoader:\n",
    "The dataset class converts each 2D slice into a tensor with shape [1, H, W]. The DataLoader batches these samples.\n",
    "\n",
    "Model Training:\n",
    "A 2D U‑Net is trained on these 2D slices using MSE loss and the Adam optimizer. The training loop over 20 epochs minimizes the loss.\n",
    "\n",
    "Model Saving:\n",
    "The trained model’s weights are saved for later use in inference (for example, to super-resolve new LR images).\n",
    "\n",
    "Super-Resolution Context:\n",
    "In a super-resolution task, you use LR slices as input and the corresponding HR slices as the target. The model learns to map the low-quality, upsampled LR slices to the high-quality HR slices. Later, during inference, you can apply the model slice-by-slice to a new volume and then reassemble the 2D outputs into a full 3D volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff5317-4488-4b81-ad98-658c1e576400",
   "metadata": {},
   "source": [
    "Concatenating Slices from Different Views:\n",
    "By concatenating axial and coronal slices into one array, you're effectively treating each 2D slice as an independent training sample. This means your training set will include slices from different anatomical views. Although they come from different orientations, the network will learn the mapping from low-resolution to high-resolution on a per-slice basis. For a baseline or overfitting experiment, this is fine.\n",
    "\n",
    "Data Shape for 2D U‑Net:\n",
    "In your dataset class, each 2D slice is converted to a tensor of shape \n",
    "[1,H,W] (1 channel, height, width). When the DataLoader batches these samples, you'll get an input of shape \n",
    "[B,1,H,W].\n",
    "\n",
    "Your model is instantiated as:\n",
    "\n",
    "UNet2D(in_channels=1, out_channels=1)  \n",
    "This is exactly what the model expects—a single-channel 2D image per sample.\n",
    "\n",
    "Considerations:\n",
    "\n",
    "Heterogeneity: The network will see slices from both axial and coronal views. While this can be useful for a more diverse training set, keep in mind that the network might have to learn different mappings if the appearance of these views differs significantly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6682e4ba-ef8a-4801-8895-bd9e842efda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/128 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 3, 3], expected input[1, 4, 176, 256] to have 1 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 131\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved as superres_unet_overfit.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 131\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[9], line 116\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m hr_tensor \u001b[38;5;241m=\u001b[39m hr_tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    115\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 116\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(lr_tensor)\n\u001b[1;32m    117\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, hr_tensor)\n\u001b[1;32m    118\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/SR-MRI/models/model.py:84\u001b[0m, in \u001b[0;36mUNetDeep.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# Encoder path\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minc(x)         \u001b[38;5;66;03m# shape: (B, 64, H, W)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(x1)      \u001b[38;5;66;03m# shape: (B, 128, H/2, W/2)\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown2(x2)      \u001b[38;5;66;03m# shape: (B, 256, H/4, W/4)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/SR-MRI/models/model.py:22\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdouble_conv(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SR-Unet-MRI/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    551\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 3, 3], expected input[1, 4, 176, 256] to have 1 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "# # train.py\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# from models.model import UNetDeep\n",
    "# # \n",
    "\n",
    "# class MRISuperResDataset(Dataset):\n",
    "#     def __init__(self, lr_volumes, hr_volumes, transform=None):\n",
    "#         \"\"\"\n",
    "#         lr_volumes and hr_volumes are lists or arrays where each element is a \n",
    "#         3D volume with shape (1, 176, 256, 256).\n",
    "#         \"\"\"\n",
    "#         self.lr_volumes = lr_volumes\n",
    "#         self.hr_volumes = hr_volumes\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.lr_volumes)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         lr_volume = self.lr_volumes[idx].astype(np.float32)\n",
    "#         hr_volume = self.hr_volumes[idx].astype(np.float32)\n",
    "\n",
    "#         # Convert to torch tensors\n",
    "#         lr_tensor = torch.from_numpy(lr_volume)\n",
    "#         hr_tensor = torch.from_numpy(hr_volume)\n",
    "\n",
    "#         if self.transform:\n",
    "#             lr_tensor = self.transform(lr_tensor)\n",
    "#             hr_tensor = self.transform(hr_tensor)\n",
    "\n",
    "#         return lr_tensor, hr_tensor\n",
    "\n",
    "\n",
    "        \n",
    "# def update_learning_rate(schedulers, val_loss):\n",
    "#     \"\"\"\n",
    "#     Update the learning rate for each scheduler.\n",
    "    \n",
    "#     For schedulers of type ReduceLROnPlateau, use scheduler.step(val_loss),\n",
    "#     otherwise, call scheduler.step() without arguments.\n",
    "    \n",
    "#     Parameters:\n",
    "#       schedulers (list): List of learning rate scheduler objects.\n",
    "#       val_loss (float): The validation loss used by ReduceLROnPlateau.\n",
    "#     \"\"\"\n",
    "#     for scheduler in schedulers:\n",
    "#         if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "#             scheduler.step(val_loss)\n",
    "#         else:\n",
    "#             scheduler.step()\n",
    "\n",
    "# def main():\n",
    "#     # 1) Load pre-saved 2D slices (uncomment these lines)\n",
    "#     slices_lr_axial = np.load(\"data/lr_slices_axial.npy\", allow_pickle=True)\n",
    "#     slices_hr_axial = np.load(\"data/hr_slices_axial.npy\", allow_pickle=True)\n",
    "#     slices_lr_coronal = np.load(\"data/lr_slices_coronal.npy\", allow_pickle=True)\n",
    "#     slices_hr_coronal = np.load(\"data/hr_slices_coronal.npy\", allow_pickle=True)\n",
    "#     slices_lr_sagittal = np.load(\"data/lr_slices_sagittal.npy\", allow_pickle=True)\n",
    "#     slices_hr_sagittal = np.load(\"data/hr_slices_sagittal.npy\", allow_pickle=True)\n",
    "\n",
    "#     # Stack the list of 2D slices along a new axis (axis 0) to form a 3D volume.\n",
    "#     # For example, if there are 176 slices, each volume will be (176, 256, 256)\n",
    "#     lr_volume_axial    = np.stack(slices_lr_axial, axis=0)\n",
    "#     lr_volume_coronal  = np.stack(slices_lr_coronal, axis=0)\n",
    "#     lr_volume_sagittal = np.stack(slices_lr_sagittal, axis=0)\n",
    "    \n",
    "#     hr_volume_axial    = np.stack(slices_hr_axial, axis=0)\n",
    "#     hr_volume_coronal  = np.stack(slices_hr_coronal, axis=0)\n",
    "#     hr_volume_sagittal = np.stack(slices_hr_sagittal, axis=0)\n",
    "    \n",
    "#     # # Add a channel dimension so that each sample becomes shape (1, 176, 256, 256)\n",
    "#     # lr_volume_axial    = np.expand_dims(lr_volume_axial, axis=0)\n",
    "#     # lr_volume_coronal  = np.expand_dims(lr_volume_coronal, axis=0)\n",
    "#     # lr_volume_sagittal = np.expand_dims(lr_volume_sagittal, axis=0)\n",
    "    \n",
    "#     # hr_volume_axial    = np.expand_dims(hr_volume_axial, axis=0)\n",
    "#     # hr_volume_coronal  = np.expand_dims(hr_volume_coronal, axis=0)\n",
    "#     # hr_volume_sagittal = np.expand_dims(hr_volume_sagittal, axis=0)\n",
    "\n",
    "#     all_lr_volumes = np.concatenate((slices_lr_axial, slices_lr_coronal), axis=0)\n",
    "#     all_hr_volumes = np.concatenate((slices_hr_axial, slices_hr_coronal), axis=0)\n",
    "\n",
    "#     # Create Dataset and DataLoader\n",
    "#     train_dataset = MRISuperResDataset(all_lr_volumes, all_hr_volumes)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # batch size 1 for overfitting\n",
    "\n",
    "    \n",
    "#     # Initialize the model\n",
    "#     model = UNetDeep(in_channels=1, out_channels=1)\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Define loss & optimizer\n",
    "#     criterion = nn.MSELoss()  # aiming for near-zero error (overfitting)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "    \n",
    "#     num_epochs = 1  # Increase epochs to fully overfit\n",
    "#     model.train()\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         running_loss = 0.0\n",
    "#         loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "#         for lr_tensor, hr_tensor in loop:\n",
    "#             lr_tensor = lr_tensor.to(device)\n",
    "#             hr_tensor = hr_tensor.to(device)\n",
    "    \n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(lr_tensor)\n",
    "#             loss = criterion(outputs, hr_tensor)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "    \n",
    "#             running_loss += loss.item()\n",
    "#             loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "#         epoch_loss = running_loss / len(train_loader)\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss: {epoch_loss:.6f}\")\n",
    "    \n",
    "#     torch.save(model.state_dict(), \"superres_unet_overfit.pth\")\n",
    "#     print(\"Model saved as superres_unet_overfit.pth\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839daf72-7e26-4908-9734-aaee2a37ddfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
